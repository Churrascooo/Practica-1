{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPZxDxcjZqB62/Tsq1qebzf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Churrascooo/Practica-1/blob/main/Trabajo1/DesafioPractica.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1) Extracción/Limpieza/Conteo"
      ],
      "metadata": {
        "id": "UjvQXeuEIJpl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### - *Librerías/Herramientas/Extracción*"
      ],
      "metadata": {
        "id": "0LyVaL3m9svp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "uiNNekvwoIl3"
      },
      "outputs": [],
      "source": [
        "#Bloque 1 - Librerías\n",
        "\n",
        "!pip -q install pdfplumber #Esta librería se dedica a leer PDFs y extraer texto de estos PDFs\n",
        "!pip -q install scikit-learn #Librería para búsqueda semántica\n",
        "!pip -q install transformers sentencepiece accelerate #Librería para cargar modelos de lenguaje y transformar texto en tokens\n",
        "!pip -q install nltk #Librería que se usará para las stopwords"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Bloque 2 - Importación de herramientas\n",
        "\n",
        "import re   #Esta herramienta sirve para trabajar con expresiones regulares"
      ],
      "metadata": {
        "id": "we8x-smW9Nf3"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Bloque 3 - Lectura del PDF\n",
        "\n",
        "import pdfplumber            #Se importa la carpeta previamente instalada\n",
        "pdf_path = \"paper.pdf\"       #Se renombra el paper como \"pdf_path\" para tener un nombre que sirva para todo\n",
        "\n",
        "texto_total = \"\"\n",
        "with pdfplumber.open(pdf_path) as pdf:              #Se usa '.open' para abrir el pdf subido\n",
        "    for i, page in enumerate(pdf.pages, start=1):   #Se usa un bucle (comenzando desde la 1 página) para ir página por página leyendo\n",
        "        page_text = page.extract_text() or \"\"       #Extrae el texto de las páginas que va iterando. El or \"\" es en caso que haya una página en blanco, se evitan errores\n",
        "        texto_total += page_text + \"\\n\"             #Se va ir guardando todo en \"texto_total, en un solo texto\n",
        "\n",
        "print(\"Páginas leídas:\", i)\n",
        "print(\"Caracteres extraídos:\", len(texto_total))\n",
        "\n",
        "print(\"\\n--- MUESTRA (primeros 800 caracteres) ---\\n\")   #Se usaron los 800 primeros caracteres para verlos bien en el printeo\n",
        "print(texto_total[:800])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "92zdY3_H6mbR",
        "outputId": "6448be9d-3d42-42ba-e17c-93b595c9b5a0"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Páginas leídas: 11\n",
            "Caracteres extraídos: 29255\n",
            "\n",
            "--- MUESTRA (primeros 800 caracteres) ---\n",
            "\n",
            "Attention Is All You Need\n",
            "AshishVaswani∗ NoamShazeer∗ NikiParmar∗ JakobUszkoreit∗\n",
            "GoogleBrain GoogleBrain GoogleResearch GoogleResearch\n",
            "avaswani@google.com noam@google.com nikip@google.com usz@google.com\n",
            "LlionJones∗ AidanN.Gomez∗ † ŁukaszKaiser∗\n",
            "GoogleResearch UniversityofToronto GoogleBrain\n",
            "llion@google.com aidan@cs.toronto.edu lukaszkaiser@google.com\n",
            "IlliaPolosukhin∗ ‡\n",
            "illia.polosukhin@gmail.com\n",
            "Abstract\n",
            "Thedominantsequencetransductionmodelsarebasedoncomplexrecurrentor\n",
            "convolutionalneuralnetworksthatincludeanencoderandadecoder. Thebest\n",
            "performing models also connect the encoder and decoder through an attention\n",
            "mechanism. We propose a new simple network architecture, the Transformer,\n",
            "basedsolelyonattentionmechanisms,dispensingwithrecurrenceandconvolutions\n",
            "entirely. Experiments on two mach\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### - *Limpieza*"
      ],
      "metadata": {
        "id": "ljlMTESiIvOP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Bloque 4 - Minúsculas\n",
        "\n",
        "texto_limpio = texto_total.lower()"
      ],
      "metadata": {
        "id": "8zqGUM5b99l4"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Bloque 5 - Eliminar caracteres especiales\n",
        "\n",
        "#re.sub se utiliza para buscar un patrón en el texto y reemplazarlo por otro.\n",
        "#n este caso, se reemplaza cualquier carácter que NO sea una letra (a–z)\n",
        "texto_limpio = re.sub(r\"[^a-z\\s]\", \" \", texto_limpio)\n",
        "\n",
        "# [a-z] -> Coincide con letras minúsculas desde la a hasta la z\n",
        "# [\\s] -> Coincide con cualquier espacio en blanco (espacio, salto de línea, tabulación)\n",
        "# [^ ] -> Selecciona todo lo que NO sea una letra ni un espacio"
      ],
      "metadata": {
        "id": "JFXTWvgL-OEd"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Bloque 6 - Limpieza de espacios\n",
        "\n",
        "texto_limpio = re.sub(r\"\\s+\", \" \", texto_limpio).strip()\n",
        "\n",
        "# .sub es una función que está dentro de la herramienta re\n",
        "# r\"\\s+\" lo que hace es ver todos los espacios y saltos de línea que hay, para convertirlos en un sólo espacio\n",
        "# .strip lo que hace es borrar los espacios al inicio y final del texto"
      ],
      "metadata": {
        "id": "dSmtK9DW-3tu"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Bloque 7 - Printeo de resultados\n",
        "\n",
        "print(\"Caracteres antes:\", len(texto_total))\n",
        "print(\"Caracteres después:\", len(texto_limpio))\n",
        "\n",
        "print(\"\\n--- MUESTRA LIMPIA (primeros 800 caracteres) ---\\n\")\n",
        "print(texto_limpio[:800])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "SpBB-yiO_7Kl",
        "outputId": "1c28845f-25bd-4bbd-f1b0-e3a4323d66f2"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Caracteres antes: 29255\n",
            "Caracteres después: 26808\n",
            "\n",
            "--- MUESTRA LIMPIA (primeros 800 caracteres) ---\n",
            "\n",
            "attention is all you need ashishvaswani noamshazeer nikiparmar jakobuszkoreit googlebrain googlebrain googleresearch googleresearch avaswani google com noam google com nikip google com usz google com llionjones aidann gomez ukaszkaiser googleresearch universityoftoronto googlebrain llion google com aidan cs toronto edu lukaszkaiser google com illiapolosukhin illia polosukhin gmail com abstract thedominantsequencetransductionmodelsarebasedoncomplexrecurrentor convolutionalneuralnetworksthatincludeanencoderandadecoder thebest performing models also connect the encoder and decoder through an attention mechanism we propose a new simple network architecture the transformer basedsolelyonattentionmechanisms dispensingwithrecurrenceandconvolutions entirely experiments on two machine translation ta\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### - *Conteo*"
      ],
      "metadata": {
        "id": "-wqMpXghI16l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Bloque 8 - Separar texto en palabras\n",
        "\n",
        "palabras = texto_limpio.split(\" \")   # .split(\" \") separa por espacios\n",
        "\n",
        "print(\"Cantidad total de palabras:\", len(palabras))\n",
        "print(\"Muestra:\", palabras[:20])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wLhKmO9mI5AY",
        "outputId": "5d466ad9-a2f9-46af-e7cd-ee347eaf6965"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cantidad total de palabras: 1848\n",
            "Muestra: ['attention', 'is', 'all', 'you', 'need', 'ashishvaswani', 'noamshazeer', 'nikiparmar', 'jakobuszkoreit', 'googlebrain', 'googlebrain', 'googleresearch', 'googleresearch', 'avaswani', 'google', 'com', 'noam', 'google', 'com', 'nikip']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Bloque 9 - Stopwords\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "nltk.download(\"stopwords\")\n",
        "\n",
        "#Se le asigna el idioma del pdf\n",
        "IDIOMA_STOPWORDS = \"english\"\n",
        "\n",
        "stop_words = set(stopwords.words(IDIOMA_STOPWORDS))\n",
        "\n",
        "print(\"Idioma stopwords:\", IDIOMA_STOPWORDS)\n",
        "print(\"Cantidad stopwords:\", len(stop_words))\n",
        "print(\"Muestra:\", list(stop_words)[:20])"
      ],
      "metadata": {
        "id": "TR8tBxKsK3DQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56253e91-a982-47f5-9aec-2ea242d907f7"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Idioma stopwords: english\n",
            "Cantidad stopwords: 198\n",
            "Muestra: ['all', 'needn', \"they're\", 'our', 'aren', \"isn't\", 'under', 'because', 'out', 'now', 'other', 'where', 'did', 'into', 'he', \"didn't\", 'down', 'its', 't', \"it'll\"]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Bloque 10 - Filtrar la stop-words\n",
        "\n",
        "palabras_filtradas = [\n",
        "    p for p in palabras\n",
        "    if p not in stop_words and len(p) > 2\n",
        "]\n",
        "\n",
        "print(\"Palabras tras filtrar:\", len(palabras_filtradas))\n",
        "print(\"Muestra filtrada:\", palabras_filtradas[:20])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2DJ3oLn8LFEG",
        "outputId": "c4e1bd4c-0c0b-4e9f-b256-8f4080ff2b34"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Palabras tras filtrar: 1410\n",
            "Muestra filtrada: ['attention', 'need', 'ashishvaswani', 'noamshazeer', 'nikiparmar', 'jakobuszkoreit', 'googlebrain', 'googlebrain', 'googleresearch', 'googleresearch', 'avaswani', 'google', 'com', 'noam', 'google', 'com', 'nikip', 'google', 'com', 'usz']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Bloque 11 - Conteo de palabras frecuentes\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "contador = Counter(palabras_filtradas)"
      ],
      "metadata": {
        "id": "Kcp9c9eZLOaq"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Bloque 12 - Mostrar las 5 palabras más frecuentes\n",
        "\n",
        "top_5 = contador.most_common(5)\n",
        "\n",
        "print(\"Top 5 palabras más frecuentes:\\n\")\n",
        "for palabra, frecuencia in top_5:\n",
        "    print(f\"{palabra} → {frecuencia}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N9mopb_ALT0Z",
        "outputId": "318297dc-ab4c-42dc-dbb4-239b008c78ff"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 palabras más frecuentes:\n",
            "\n",
            "attention → 21\n",
            "model → 14\n",
            "layer → 12\n",
            "self → 11\n",
            "layers → 11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2) Búsqueda semántica simple"
      ],
      "metadata": {
        "id": "DwxbPF5_Lp_n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Bloque 13 - Dividir el texto en chunks\n",
        "\n",
        "CHUNK_SIZE = 500 #Se define el tamaño en 500 carácteres de cada bloque de texto\n",
        "\n",
        "chunks = [\n",
        "    texto_limpio[i:i + CHUNK_SIZE] #Se crean los chunks dividiendo el texto limpio\n",
        "    for i in range(0, len(texto_limpio), CHUNK_SIZE) #Se recorre el texto de 0 al final, avanzando por cada CHUNK_SIZE,\n",
        "]                                                    #y en cada iteración se corta un trozo de 500 caracteres\n",
        "\n",
        "print(\"Chunks creados:\", len(chunks)) #Se printea cuantos trozos se generaron, para verificar que el texto fue bien dividido\n",
        "print(\"Largo del primer chunk:\", len(chunks[0])) #Se printea el largo del primer chunk para saber si los demás estarán bien\n",
        "print(\"\\n--- CHUNK 0 (primeros 500 caracteres) ---\\n\") #Se printean los primeros 500 carácteres\n",
        "print(chunks[0][:500])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SN2PNJwgLwMc",
        "outputId": "799802af-29cd-4e60-8d96-e7299cfab9b4"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chunks creados: 54\n",
            "Largo del primer chunk: 500\n",
            "\n",
            "--- CHUNK 0 (primeros 500 caracteres) ---\n",
            "\n",
            "attention is all you need ashishvaswani noamshazeer nikiparmar jakobuszkoreit googlebrain googlebrain googleresearch googleresearch avaswani google com noam google com nikip google com usz google com llionjones aidann gomez ukaszkaiser googleresearch universityoftoronto googlebrain llion google com aidan cs toronto edu lukaszkaiser google com illiapolosukhin illia polosukhin gmail com abstract thedominantsequencetransductionmodelsarebasedoncomplexrecurrentor convolutionalneuralnetworksthatinclud\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Bloque 14 - Buscar qué parte del texto se parece a la pregunta hecha por el usuario\n",
        "\n",
        "import numpy as np #Se importa la carpeta numpy para operaciones numéricas\n",
        "\n",
        "#Importación de las herramientas de NLP clásico\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer #Esto es TF-IDF, para convertir texto en vectores de números\n",
        "from sklearn.metrics.pairwise import cosine_similarity #Esto es la distancia del coseno, para ver que tan parecidos son los vectores anteriores\n",
        "\n",
        "\n",
        "def top_k_chunks(chunks, query, k=3): #Esta función es para encontrar los k chunks más similares\n",
        "                                      #a la pregunta del usuario, usando TD-IDF y distancia de coseno\n",
        "\n",
        "    #chunks -> lista de fragmentos de texto del documento\n",
        "    #query -> pregunta del usuario\n",
        "    #k -> número de fragmentos más relevantes a devolver\n",
        "\n",
        "    textos = chunks + [query] #Se unen todos los chunks con la query, en una sola lista\n",
        "                              #Gracias a esto TF-IDF generará un vocabulario común\n",
        "\n",
        "    vectorizer = TfidfVectorizer() #Se inicia el vectorizador TD-IDF\n",
        "    tfidf = vectorizer.fit_transform(textos) #Se ajusta el vectorizados y se comienza a transformar los textos en vectores numéricos\n",
        "    sims = cosine_similarity(tfidf[-1], tfidf[:-1]).flatten() #Se calcula la similitud entre coseno y query en la última fila\n",
        "                                                              #También la de todos los chunks, menos la última fila\n",
        "\n",
        "    top_idx = np.argsort(sims)[::-1][:k] #Se consiguen los índices de los k valores que tengan mayor similitud\n",
        "                                         #argsort ordena de menor a mayor, entonces se usa el ::-1 para dar vuelta eso\n",
        "\n",
        "    return [(int(i), float(sims[i]), chunks[i]) for i in top_idx] #Se devuelve una con el índice del chunk, el puntaje de similitud y el texto al que corresponde\n",
        "\n",
        "query = input(\"Escribe tu pregunta: \").strip() #El usuario escribe la pregunta por consola\n",
        "                                               #Ejemplo que sirvió: What is the transformer architecture?\n",
        "if not query:\n",
        "    raise ValueError(\"La pregunta no puede estar vacía\")\n",
        "\n",
        "\n",
        "top3 = top_k_chunks(chunks, query, k=3) #Se crea una variable donde de obtendrá los 3 fragmentos más parecidos para responder la pregunta\n",
        "\n",
        "#Se muestran los resultados ordenados por relevancia\n",
        "for rank, (i, s, ch) in enumerate(top3, start=1):\n",
        "    print(f\"\\n=== TOP {rank} ===\")\n",
        "    print(\"idx:\", i, \"| score:\", s)\n",
        "    print(ch[:400], \"...\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a6f2J6h8V6US",
        "outputId": "40d1b77a-e400-48fe-f2a6-f11f4e3f55fb"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Escribe tu pregunta: What is the transformer architecture\n",
            "\n",
            "=== TOP 1 ===\n",
            "idx: 10 | score: 0.18619212516790978\n",
            "le languagequestionansweringand languagemodelingtasks to the best of our knowledge however the transformer is the first transduction model relying entirelyonself attentiontocomputerepresentationsofitsinputandoutputwithoutusingsequence alignedrnnsorconvolution inthefollowingsections wewilldescribethetransformer motivate self attentionanddiscussitsadvantagesovermodelssuchas and modelarchitecture mos ...\n",
            "\n",
            "=== TOP 2 ===\n",
            "idx: 1 | score: 0.16333071944615513\n",
            "eanencoderandadecoder thebest performing models also connect the encoder and decoder through an attention mechanism we propose a new simple network architecture the transformer basedsolelyonattentionmechanisms dispensingwithrecurrenceandconvolutions entirely experiments on two machine translation tasks show these models to besuperiorinqualitywhilebeingmoreparallelizableandrequiringsignificantly le ...\n",
            "\n",
            "=== TOP 3 ===\n",
            "idx: 30 | score: 0.14651510439879295\n",
            " requires o n sequential operations in terms of computationalcomplexity self attentionlayersarefasterthanrecurrentlayerswhenthesequence length n is smaller than the representation dimensionality d which is most often the case with sentencerepresentationsusedbystate of the artmodelsinmachinetranslations suchasword piece andbyte pair representations toimprovecomputationalperformancefortasksinvolving ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3) Intento de generación de respuesta"
      ],
      "metadata": {
        "id": "oLxxIRqR_M62"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Bloque 15 - Carga de modelo y transformar texto a tokens\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM #De la librería se importa la función que se usará\n",
        "model_name = \"google/flan-t5-small\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name) #Acá se convierte el texto en números\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name) #Acá se usa el modelo que genera texto"
      ],
      "metadata": {
        "id": "x5u_cOUI_S9e"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Bloque 16 - Funciones para generar la respuesta\n",
        "\n",
        "def generar_respuesta(query, contexto, max_new_tokens=120): #Se crea la función para generar una respuesta a la pregunta\n",
        "                                                            #Se usa un fragmento del texto como contexto para responder\n",
        "\n",
        "    prompt = (\"Answer the question using only the context below.\\n\\n\"  #Se hace un prompt donde se dice que responda solo usando\n",
        "        f\"Context:\\n{contexto}\\n\\n\"                                    #el contexto dado, asi no tira información errónea o inventada\n",
        "        f\"Question: {query}\\n\"\n",
        "        \"Answer:\"\n",
        "    )\n",
        "\n",
        "    inputs = tokenizer( #Se convierte el texto del prompt en tokens, para que el modelo procese\n",
        "        prompt,\n",
        "        return_tensors = \"pt\", #Se devuelven los tensores de PyTorch (librería). El tensor es como un arreglo pero pensado para IA\n",
        "        truncation = True, #En caso que el texto sea muy largo, lo trunca\n",
        "        max_length = 512 #Se establece 512 como límite máximo de tokens de entrada\n",
        "    )\n",
        "\n",
        "    outputs = model.generate( #Se genera una respuesta usando el modelo de lenguaje\n",
        "        **inputs,\n",
        "        max_new_tokens=max_new_tokens, #Esto es para controlar el largo de la respuesta\n",
        "        do_sample=False #Hace la generación determinista, es decir, el modelo elige siempre la opción más probable en cada paso\n",
        "                        #Esto es para hacer una respuesta estable y que no vaya cambiando\n",
        "    )\n",
        "\n",
        "    return tokenizer.decode(outputs[0], skip_special_tokens=True) #Se transforma los tokens a texto, y se eliminan tokens especiales que hayan del modelo"
      ],
      "metadata": {
        "id": "Nkp4VvMvBJ85"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Bloque 17 - Respuesta\n",
        "\n",
        "mejor_contexto = top3[0][2] #Se usa el chunk más relevante encontrado antes\n",
        "\n",
        "respuesta = generar_respuesta(query, mejor_contexto) #Se genera la respuesta, en donde se usa\n",
        "                                                     #la pregunta del usuario y el fragmento más relevante, como contexto\n",
        "\n",
        "print(\"Pregunta:\") #Se printea la pregunta del usuario\n",
        "print(query)\n",
        "\n",
        "print(\"\\nRespuesta generada:\") #Se printea la respuesta que generó el modelo\n",
        "print(respuesta)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JkEy5tjyCZJQ",
        "outputId": "e7597cb9-8ca5-4b3f-c8aa-3172ba8fa900"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pregunta:\n",
            "What is the transformer architecture\n",
            "\n",
            "Respuesta generada:\n",
            "the first transduction model relying entirely on self attention to computer presentations of its input and output without using sequence aligned rnns or convolution in the following sections we will describe the transformer motivate self attention and discusses its advantages over models such as and model architecture most competitive neural sequence transduction models have an encoder decoder structure here the encoder maps an\n"
          ]
        }
      ]
    }
  ]
}